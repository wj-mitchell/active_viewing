df_recall_wide$NoJon_Avg[ceiling(Halfway):nrow(df_recall_wide)] <- rowMeans(df_recall_wide[ceiling(Halfway):nrow(df_recall_wide),
which(names(df_recall_wide) %in% NoJon_SH)],
na.rm = T)
df_long <- df_recall_wide %>%
pivot_longer(cols = starts_with("SR-"),
names_to = "PID",
values_to = "Recalled") %>%
select(c(PID,Scene,Recalled))
df_qual <- df_qual %>%
select(c(PID,Rated)) %>%
subset(!is.na(.$Rated))
df_long <- merge(df_long,df_qual, by = "PID")
df_long$Half <- NA
df_long$Half[df_long$Scene < 20] <- "First"
df_long$Half[df_long$Scene > 19] <- "Last"
df_long$Congruent <- NA
df_long$Congruent[df_long$Rated == df_long$Half] <- "Rated"
df_long$Congruent[df_long$Rated != df_long$Half] <- "Not Rated"
df_long$Recalled[df_long$Recalled == 1] <- "Recalled"
df_long$Recalled[df_long$Recalled == 0] <- "Not Recalled"
chisq.test(x = df_long$Congruent,
y = df_long$Recalled)
df_long$Recalled_Cat <- 0
df_long$Recalled_Cat[df_long$Recalled == "Recalled"] <- 1
df_summary <- df_long %>%
group_by(PID, Congruent) %>%
summarize(Proportion_Recalled = mean(Recalled_Cat == 1, na.rm = TRUE))
t.test(x = df_summary$Proportion_Recalled[df_summary$Congruent == "Rated"],
y = df_summary$Proportion_Recalled[df_summary$Congruent == "Not Rated"],
paired = T)
plot <- ggplot(data = df_long, aes(x = Congruent, color = Recalled, fill = Recalled)) +
geom_bar() +
# scale_x_discrete("Condition") +
scale_y_continuous(breaks = c(0,100,200,300,400)) +
labs(
x = NULL,
y ="Frequency") +
scale_color_brewer() +
scale_fill_brewer(palette = "Accent") +
coord_cartesian(ylim=c(0.0, 425.0)) +
theme_classic() +
theme(plot.title = element_text(face="bold", size=8, hjust = 0.5)) +
theme(plot.subtitle = element_text(size = 10, hjust = 0.5, face = "italic")) +
theme(plot.caption = element_text(size = 8, hjust = 0.0, face = "italic")) +
theme(axis.title = element_text(size = 10)) +
theme(axis.text.x = element_text(size = 14, color = "Black")) +
theme(axis.text.y = element_text(size = 12, color = "Black")) +
theme(legend.key.size = unit(0.5, 'cm')) +
theme(legend.title = element_text(size=8)) +
theme(legend.text = element_text(size=6))
plot
View(df_long)
## If the pacman package manager is not currently installed on this system, install it.
if (require("pacman") == FALSE){
install.packages("pacman")
}
## Loading in my packages with my pacman manager
pacman::p_load(corrplot,
here,
lme4,
lmerTest,
performance,
reshape2,
tibble,
tidyverse)
## Setting Working Directory
(dir_Work <- here::here())
## Loading in our custom cleaner function
source(paste0(dir_Work,"/2_Analysis/func_RatingCor.R"))
# First half ends at Event 19, Second Half starts at Event 20
Halfway <- 19.5
## Using the custom cleaner function on First Half Raters
df_FH <- Rating_Cor(Data = paste0(dir_Work, "/3_Data/Ratings/df_behav.csv"),
Cond = "A",
SceneBreaks = c(0, 189, 241, 243, 419,
431, 521, 527, 581, 625,
757, 797, 827, 877, 885,
983, 1133, 1273, 1291, 1337),
RunCor = F) %>%
t() %>%
as.data.frame()
## Saving the PIDs of first half raters
raters_FH <- colnames(df_FH)
## Adding a Scene variable
df_FH$Scene <- 1:nrow(df_FH)
## Pivoting the dataframe wider
df_FH <- df_FH %>%
pivot_longer(cols = !Scene,
names_to = "PID",
values_to = "Rating")
## Using the custom cleaner function on First Half Raters
df_SH <- Rating_Cor(Data = paste0(dir_Work, "/3_Data/Ratings/df_behav.csv"),
Cond = "B",
SceneBreaks = c(0, 14, 28, 75, 158,
186, 279, 283, 335,
398, 405, 681, 877,
604, 1062, 1067, 1337),
RunCor = F) %>%
t() %>%
as.data.frame()
## Saving the PIDs of first half raters
raters_SH <- colnames(df_SH)
## Adding a Scene variable
df_SH$Scene <- ceiling(Halfway):(floor(Halfway) + nrow(df_SH))
## Pivoting the dataframe wider
df_SH <- df_SH %>%
pivot_longer(cols = !Scene,
names_to = "PID",
values_to = "Rating")
# Binding the dataframes together for First and Second Half Raters
df_rating <- rbind(df_FH,
df_SH)
# Cleaning our space
rm(df_FH,df_SH)
# Z scoring ratings
df_rating$Rating_z <- df_rating$Rating %>%
scale() %>%
as.numeric()
# Creating an average rating per scene
rating_per_scene <- df_rating %>%
group_by(Scene) %>%
summarise(average_rating = mean(Rating_z)) %>%
.[,2] %>%
unlist() %>%
as.numeric() %>%
as.array()
## From this we want to know who participants had thought had done it at the end of each section
df_qual <- read.csv(paste0(dir_Work, "/3_Data/Qualtrics/df_qualtrics.csv")) %>%
select("PID", "TheoryMid", "TheoryEnd")
## Renaming those columns
names(df_qual) <- c("PID", "Mid_Theory", "End_Theory")
## Reducing dimentionality
df_qual$Mid_Theory[df_qual$Mid_Theory != "Jonathan Fraser"] <- "Not Jonathan Fraser"
df_qual$End_Theory[df_qual$End_Theory != "Jonathan Fraser"] <- "Not Jonathan Fraser"
## Noting who rated which half
df_qual$Rated <- NA
df_qual$Rated[which(df_qual$PID %in% raters_FH)] <- "First"
df_qual$Rated[which(df_qual$PID %in% raters_SH)] <- "Last"
df_recall <- read.csv(paste0(dir_Work,"/3_Data/Recall/df_recall.csv")) %>%
# Remove all rows in which every value is NA
na.omit()
# Save every unique PID as a variable
PIDs <- unique(df_recall$PID)
# Specifying the names of rows and columns in the new dataframe
cols <- c("PID", "Scene", "Recalled")
rows <- 1:((length(PIDs)) * 35)
# Creating  the new dataframe
df_recall_wide <- as.data.frame(matrix(NA,
nrow = length(rows),
ncol =  length(cols),
dimnames = list(rows,
cols)))
# Cleaning space
rm(cols,rows)
# Repeating the numbers 1 through 35 a number of times equivalent to the number of unique PIDs there are
df_recall_wide$Scene <- PIDs %>%
length() %>%
rep(1:35, .)
# Repeating each of the unique PIDs a number of times equivalent to the number of scenes there are and sorting them alphanumerically
df_recall_wide$PID <- PIDs %>%
rep(., 35) %>%
sort()
# Make all data equal to 0
df_recall_wide$Recalled <- 0
# Iterate through every PID
for (PID in PIDs){
# Iterate through every scene
for (SCENE in unique(df_recall_wide$Scene)){
# If any PID / Scene combo is present in the original dataframe
if (any(df_recall$PID == PID & df_recall$Scenes == SCENE)){
# Then find that PID / Scene Combo in the new dataframe and change the 0 to a 1
df_recall_wide$Recalled[df_recall_wide$PID == PID & df_recall_wide$Scene == SCENE] <- 1
}
}
}
#
# # Iterate through participant
# for (PID in PIDs){
#
#   # Set the order tracker to 1
#   tracker <- 1
#
#   # Create a temporary dataframe of only this participant's observations
#   df_temp <- df_recall[df_recall$PID == PID,]
#
#   # Iterate through the rows of the temporary dataframe
#   for (ROW in 1:nrow(df_temp)){
#
#     # Record the order that each scene was recalled within
#     df_recall_wide$Order[df_recall_wide$PID == PID & df_recall_wide$Scene == df_temp$Scenes[ROW]] <- tracker
#
#     # Increment the tracker by 1
#     tracker <- tracker + 1
#   }
#
#   # NOTE: Subjects recalling different numbers of events means that the raw numbers may not be comparable. The last event recalled for one subject might be the 18th event while the same event might be  the 22nd for another subject. As a result, we're going to do a relative order adjustment, which is effectively just dividing the raw order value by the total number of events recalled by this subject.
#   # Adjusting the order values according to the tracker maximum, in case we want to keep variance standard across participants
#   df_recall_wide$Order_Adj[df_recall_wide$PID == PID] <- df_recall_wide$Order[df_recall_wide$PID == PID] / tracker
#
#   # Reset our variables
#   rm(tracker, df_temp)
# }
#
# ## Cleaning Space
# rm(PID, SCENE)
# Patching up the PID variable names (Can't have variable names that start with numbers)
df_recall_wide$PID <- paste0("SR-", sprintf("%04d", as.integer(df_recall_wide$PID)))
PIDs <- paste0("SR-", sprintf("%04d", PIDs))
# Pivoting to a wider format
df_recall_wide <- pivot_wider(df_recall_wide,
names_from = PID,
values_from = Recalled)
# Calculating the average relative order of each scene
df_recall_wide$GroupAvg <- rowMeans(df_recall_wide[,2:ncol(df_recall_wide)], na.rm = T)
# Removing B-Roll; I checked and not a single one of these ever got recalled.
# I'm worried leaving these in is misleading; it leads people to think there's more variance around major show events than there might actually be
df_recall_wide <- df_recall_wide[-c(3,7,14,26,29,32,34),]
# Plotting
plot(df_recall_wide$Scene, df_recall_wide$GroupAvg, type = "l")
# Removing B-Roll Scenes
rating_per_scene <- rating_per_scene[-c(3,7,14,26,29,32,34)]
# Correlating
cor(df_recall_wide$GroupAvg, rating_per_scene)
plot(df_recall_wide$GroupAvg, rating_per_scene)
Jon_FH <- df_qual$PID[df_qual$Mid_Theory == "Jonathan Fraser"]
Jon_SH <- df_qual$PID[df_qual$End_Theory == "Jonathan Fraser"]
NoJon_FH <- df_qual$PID[df_qual$Mid_Theory == "Not Jonathan Fraser"]
NoJon_SH <- df_qual$PID[df_qual$End_Theory == "Not Jonathan Fraser"]
df_recall_wide$Jon_Avg <- NA
df_recall_wide$NoJon_Avg <- NA
df_recall_wide$Jon_Avg[1:floor(Halfway)] <- rowMeans(df_recall_wide[1:floor(Halfway),
which(names(df_recall_wide) %in% Jon_FH)],
na.rm = T)
df_recall_wide$Jon_Avg[ceiling(Halfway):nrow(df_recall_wide)] <- rowMeans(df_recall_wide[ceiling(Halfway):nrow(df_recall_wide),
which(names(df_recall_wide) %in% Jon_SH)],
na.rm = T)
df_recall_wide$NoJon_Avg[1:floor(Halfway)] <- rowMeans(df_recall_wide[1:floor(Halfway),
which(names(df_recall_wide) %in% NoJon_FH)],
na.rm = T)
df_recall_wide$NoJon_Avg[ceiling(Halfway):nrow(df_recall_wide)] <- rowMeans(df_recall_wide[ceiling(Halfway):nrow(df_recall_wide),
which(names(df_recall_wide) %in% NoJon_SH)],
na.rm = T)
df_long <- df_recall_wide %>%
pivot_longer(cols = starts_with("SR-"),
names_to = "PID",
values_to = "Recalled") %>%
select(c(PID,Scene,Recalled))
df_qual <- df_qual %>%
select(c(PID,Rated)) %>%
subset(!is.na(.$Rated))
df_long <- merge(df_long,df_qual, by = "PID")
df_long$Half <- NA
df_long$Half[df_long$Scene < 20] <- "First"
df_long$Half[df_long$Scene > 19] <- "Last"
df_long$Congruent <- NA
df_long$Congruent[df_long$Rated == df_long$Half] <- "Rated"
df_long$Congruent[df_long$Rated != df_long$Half] <- "Not Rated"
df_long$Recalled[df_long$Recalled == 1] <- "Recalled"
df_long$Recalled[df_long$Recalled == 0] <- "Not Recalled"
chisq.test(x = df_long$Congruent,
y = df_long$Recalled)
df_long$Recalled_Cat <- 0
df_long$Recalled_Cat[df_long$Recalled == "Recalled"] <- 1
df_summary <- df_long %>%
group_by(PID, Congruent) %>%
summarize(Proportion_Recalled = mean(Recalled_Cat == 1, na.rm = TRUE))
t.test(x = df_summary$Proportion_Recalled[df_summary$Congruent == "Rated"],
y = df_summary$Proportion_Recalled[df_summary$Congruent == "Not Rated"],
paired = T)
View(df_recall_wide)
View(df_recall)
View(df_summary)
unique(df_summary$PID)
View(df_recall)
View(df_recall_wide)
View(df_recall_wide)
df_rsa <- df_recall_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-"))
View(df_rsa)
df_rsa <- df_recall_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-")) %>%
# Step 2: Calculate pairwise correlations across all Assessment columns
cor(use = "complete.obs")
df_rsa <- df_recall_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-")) %>%
# Step 2: Calculate pairwise correlations across all Assessment columns
cor(use = "complete.obs") %>%
# Step 3: Remove the upper triangle by setting it to NA
{ .[upper.tri(., diag = TRUE)] <- NA; . } %>%
# Step 4: Melt the matrix for ggplot
melt(na.rm = TRUE)
View(df_rsa)
df_rsa <- df_recall_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-")) %>%
# Step 2: Calculate pairwise correlations across all Assessment columns
cor(use = "complete.obs") %>%
# Step 3: Remove the upper triangle by setting it to NA
{ .[upper.tri(., diag = TRUE)] <- NA; . } %>%
# Step 4: Melt the matrix for ggplot
melt(na.rm = TRUE) %>%
# Step 5: Add condition columns by joining with rating data
left_join(rating, by = c("Var1" = "Subject")) %>%
rename(Condition_Var1 = Condition) %>%
left_join(rating, by = c("Var2" = "Subject")) %>%
rename(Condition_Var2 = Condition)
rating <- paste0(dir_Work, "/3_Data/Ratings/df_behav.csv") %>%
read.csv() %>%
.[,1:2]
df_rsa <- df_recall_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-")) %>%
# Step 2: Calculate pairwise correlations across all Assessment columns
cor(use = "complete.obs") %>%
# Step 3: Remove the upper triangle by setting it to NA
{ .[upper.tri(., diag = TRUE)] <- NA; . } %>%
# Step 4: Melt the matrix for ggplot
melt(na.rm = TRUE) %>%
# Step 5: Add condition columns by joining with rating data
left_join(rating, by = c("Var1" = "Subject")) %>%
rename(Condition_Var1 = Condition) %>%
left_join(rating, by = c("Var2" = "Subject")) %>%
rename(Condition_Var2 = Condition) %>%
# Step 6: Add a column indicating if the conditions match or not
mutate(Condition_Match = ifelse(Condition_Var1 == Condition_Var2, "Match", "Do Not Match"))
rating <- paste0(dir_Work, "/3_Data/Ratings/conditions.csv") %>%
read.csv() %>%
.[,1:2]
rating <- paste0(dir_Work, "/3_Data/conditions.csv") %>%
read.csv() %>%
.[,1:2]
df_rsa <- df_recall_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-")) %>%
# Step 2: Calculate pairwise correlations across all Assessment columns
cor(use = "complete.obs") %>%
# Step 3: Remove the upper triangle by setting it to NA
{ .[upper.tri(., diag = TRUE)] <- NA; . } %>%
# Step 4: Melt the matrix for ggplot
melt(na.rm = TRUE) %>%
# Step 5: Add condition columns by joining with rating data
left_join(rating, by = c("Var1" = "Subject")) %>%
rename(Condition_Var1 = Condition) %>%
left_join(rating, by = c("Var2" = "Subject")) %>%
rename(Condition_Var2 = Condition) %>%
# Step 6: Add a column indicating if the conditions match or not
mutate(Condition_Match = ifelse(Condition_Var1 == Condition_Var2, "Match", "Do Not Match"))
View(df_rsa)
# Calculating if there's a difference by condition in a t-test
print(t.test(x = df_rsa$value[df_rsa$Condition_Match == "Match"],
y = df_rsa$value[df_rsa$Condition_Match == "Do Not Match"]))
# for reproducibility
set.seed(123)
# Assuming `similarity_matrix` is your dataframe with same/different condition categorization
observed_diff <- df_rsa %>%
group_by(Condition_Match) %>%
summarize(mean_correlation = mean(value)) %>%
spread(Condition_Match, mean_correlation) %>%
summarize(diff = `Match` - `Do Not Match`) %>%
pull(diff)
# Initialize parameters
n_permutations <- 5000
permuted_diffs <- numeric(n_permutations)
# Permutation loop
for (i in 1:n_permutations) {
# Randomly shuffle condition labels
shuffled_conditions <- sample(df_rsa$Condition_Match)
# Calculate mean difference for shuffled data
permuted_diff <- df_rsa %>%
mutate(Shuffled_Condition = shuffled_conditions) %>%
group_by(Shuffled_Condition) %>%
summarize(mean_correlation = mean(value)) %>%
spread(Shuffled_Condition, mean_correlation) %>%
summarize(diff = `Match` - `Do Not Match`) %>%
pull(diff)
# Store the permuted difference
permuted_diffs[i] <- permuted_diff
}
# Calculate p-value
p_value <- mean(abs(permuted_diffs) >= abs(observed_diff))
# Display results
cat("Observed Difference:", observed_diff, "\n")
cat("p-value:", p_value, "\n")
cat("Observed Difference:", observed_diff, "\n")
cat("p-value:", p_value, "\n")
library(tidyverse)
library(reshape2)
rating <- "C:/Users/wjpmi/Documents/GitHub/Social_Regulation/3_Data/conditions.csv" %>%
read.csv() %>%
.[,1:2]
qualtrics <- "C:/Users/wjpmi/Documents/GitHub/Social_Regulation/3_Data/Qualtrics/df_qualtrics.csv" %>%
read.csv(row.names = 1) %>%
select("PID", starts_with("Theory"), starts_with("ChrAssess_")) %>%
na.omit() %>%
merge(x = rating,
y = .,
by.x = "Subject",
by.y = "PID")
df <- qualtrics %>%
pivot_longer(cols = starts_with("ChrAssess_"),
names_to = "Category",
values_to = "Assessment") %>%
mutate(Character = str_extract(string = Category, "(?<=ChrAssess_)[^_]+"),
Category = str_extract(string = Category, "[^_]+$"))
library(tidyverse)
library(reshape2)
rating <- "C:/Users/wjpmi/Documents/GitHub/Social_Regulation/3_Data/conditions.csv" %>%
read.csv() %>%
.[,1:2]
qualtrics <- "C:/Users/wjpmi/Documents/GitHub/Social_Regulation/3_Data/Qualtrics/df_qualtrics.csv" %>%
read.csv(row.names = 1) %>%
select("PID", starts_with("Theory"), starts_with("ChrAssess_")) %>%
na.omit() %>%
merge(x = rating,
y = .,
by.x = "Subject",
by.y = "PID")
df <- qualtrics %>%
pivot_longer(cols = starts_with("ChrAssess_"),
names_to = "Category",
values_to = "Assessment") %>%
mutate(Character = str_extract(string = Category, "(?<=ChrAssess_)[^_]+"),
Category = str_extract(string = Category, "[^_]+$"))
View(df)
unique(df$Subject)
library(tidyverse)
library(reshape2)
rating <- "C:/Users/wjpmi/Documents/GitHub/Social_Regulation/3_Data/conditions.csv" %>%
read.csv() %>%
.[,1:2]
qualtrics <- "C:/Users/wjpmi/Documents/GitHub/Social_Regulation/3_Data/Qualtrics/df_qualtrics.csv" %>%
read.csv(row.names = 1) %>%
select("PID", starts_with("Theory"), starts_with("ChrAssess_")) %>%
na.omit() %>%
merge(x = rating,
y = .,
by.x = "Subject",
by.y = "PID")
df <- qualtrics %>%
pivot_longer(cols = starts_with("ChrAssess_"),
names_to = "Category",
values_to = "Assessment") %>%
mutate(Character = str_extract(string = Category, "(?<=ChrAssess_)[^_]+"),
Category = str_extract(string = Category, "[^_]+$"))
traits <- df$Category %>% unique()
characters <- df$Character %>% unique()
for (TRAIT in traits){
print(t.test(x = df$Assessment[df$Condition == "A" & df$Category == TRAIT],
y = df$Assessment[df$Condition == "B" & df$Category == TRAIT]))
}
for (CHARACTER in characters){
print(t.test(x = df$Assessment[df$Condition == "A" & df$Character == CHARACTER],
y = df$Assessment[df$Condition == "B" & df$Character == CHARACTER]))
}
# Transform to wide format
df_wide <- df %>%
select(Subject, Assessment, Category, Character) %>%
pivot_wider(names_from = Subject, values_from = Assessment)
df_rsa <- df_wide %>%
# Step 1: Select only the Assessment columns
select(starts_with("SR-")) %>%
# Step 2: Calculate pairwise correlations across all Assessment columns
cor(use = "complete.obs") %>%
# Step 3: Remove the upper triangle by setting it to NA
{ .[upper.tri(., diag = TRUE)] <- NA; . } %>%
# Step 4: Melt the matrix for ggplot
melt(na.rm = TRUE) %>%
# Step 5: Add condition columns by joining with rating data
left_join(rating, by = c("Var1" = "Subject")) %>%
rename(Condition_Var1 = Condition) %>%
left_join(rating, by = c("Var2" = "Subject")) %>%
rename(Condition_Var2 = Condition) %>%
# Step 6: Add a column indicating if the conditions match or not
mutate(Condition_Match = ifelse(Condition_Var1 == Condition_Var2, "Match", "Do Not Match"))
# Calculating if there's a difference by condition in a t-test
print(t.test(x = df_rsa$value[df_rsa$Condition_Match == "Match"],
y = df_rsa$value[df_rsa$Condition_Match == "Do Not Match"]))
# for reproducibility
set.seed(123)
# Assuming `similarity_matrix` is your dataframe with same/different condition categorization
observed_diff <- df_rsa %>%
group_by(Condition_Match) %>%
summarize(mean_correlation = mean(value)) %>%
spread(Condition_Match, mean_correlation) %>%
summarize(diff = `Match` - `Do Not Match`) %>%
pull(diff)
# Initialize parameters
n_permutations <- 5000
permuted_diffs <- numeric(n_permutations)
# Permutation loop
for (i in 1:n_permutations) {
# Randomly shuffle condition labels
shuffled_conditions <- sample(df_rsa$Condition_Match)
# Calculate mean difference for shuffled data
permuted_diff <- df_rsa %>%
mutate(Shuffled_Condition = shuffled_conditions) %>%
group_by(Shuffled_Condition) %>%
summarize(mean_correlation = mean(value)) %>%
spread(Shuffled_Condition, mean_correlation) %>%
summarize(diff = `Match` - `Do Not Match`) %>%
pull(diff)
# Store the permuted difference
permuted_diffs[i] <- permuted_diff
}
# Calculate p-value
p_value <- mean(abs(permuted_diffs) >= abs(observed_diff))
# Display results
cat("Observed Difference:", observed_diff, "\n")
cat("p-value:", p_value, "\n")
